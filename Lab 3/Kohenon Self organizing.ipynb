{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "[1, 1, 0,0],\n",
    "[0, 0, 0,1],\n",
    "[1, 0, 0,0],\n",
    "[0, 0, 1,1]])\n",
    "\n",
    "alpha=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2  0.8]\n",
      " [ 0.6  0.4]\n",
      " [ 0.5  0.7]\n",
      " [ 0.9  0.3]]\n"
     ]
    }
   ],
   "source": [
    "#w=np.random.random((len(X[0]),2))\n",
    "w=[]\n",
    "w.append([0.2,0.8])\n",
    "w.append([0.6,0.4])\n",
    "w.append([0.5,0.7])\n",
    "w.append([0.9,0.3])\n",
    "w=np.array(w)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2  0.6  0.5  0.9]\n",
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(w[:,0])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate= 0.6\n",
      "[1.8600000000000003, 0.97999999999999987]\n",
      "[0.66000000000000003, 2.2767999999999997]\n",
      "[1.8655999999999997, 0.67679999999999996]\n",
      "[0.70560000000000023, 2.724288]\n",
      "Learning Rate= 0.3\n",
      "[3.1848960000000002, 0.50028799999999995]\n",
      "[0.47289599999999993, 2.1587411200000002]\n",
      "[2.1645190400000001, 0.27074112000000011]\n",
      "[0.27971904000000003, 2.9445031488]\n",
      "Learning Rate= 0.15\n",
      "[3.2623423296, 0.41474314879999996]\n",
      "[0.4034623296, 2.143243925008]\n",
      "[2.251517533136, 0.20988392500800007]\n",
      "[0.21506153313599996, 3.01569553581828]\n",
      "Learning Rate= 0.075\n",
      "[3.26839675769076, 0.3779439358182799]\n",
      "[0.37035595769076002, 2.1366524900845159]\n",
      "[2.2854483962991567, 0.1890481900845159]\n",
      "[0.19303486629915653, 3.0454359036410636]\n",
      "Learning Rate= 0.0375\n",
      "[3.2674887457272161, 0.36100969089106383]\n",
      "[0.35472758622721584, 2.1335098290426746]\n",
      "[2.3006327249345562, 0.18015837569892468]\n",
      "[0.18366830400643167, 3.0591417024613943]\n",
      "Learning Rate= 0.01875\n",
      "[3.2663506485138099, 0.3528974813059646]\n",
      "[0.347169255595763, 2.1319703452192131]\n",
      "[2.3078380408026202, 0.17602771088541677]\n",
      "[0.17932375294323699, 3.0657334603254123]\n",
      "Learning Rate= 0.009375\n",
      "[3.2656392526048243, 0.34892823347931112]\n",
      "[0.34345557471275689, 2.1312080698684239]\n",
      "[2.3113503711826238, 0.17403406658407403]\n",
      "[0.17722873851712301, 3.0689674166070473]\n",
      "Learning Rate= 0.0046875\n",
      "[3.2652511151780557, 0.34696506855492032]\n",
      "[0.3416152205716495, 2.130828750221136]\n",
      "[2.3130847011894144, 0.1730543883597814]\n",
      "[0.17619970527871182, 3.0705693128298077]\n",
      "Learning Rate= 0.00234375\n",
      "[3.265049305557806, 0.34598881779376361]\n",
      "[0.34069917538557282, 2.1306395395197768]\n",
      "[2.3139464977022994, 0.17256874254497565]\n",
      "[0.17568970688373903, 3.0713665390192508]\n",
      "Learning Rate= 0.001171875\n",
      "[3.2649465101934552, 0.3455020211422774]\n",
      "[0.34024218681355045, 2.1305450458160653]\n",
      "[2.3143760649400593, 0.17232695664887421]\n",
      "[0.17543582500013372, 3.0717642276247661]\n",
      "Learning Rate= 0.0005859375\n",
      "[3.2648946453687158, 0.34525895447037686]\n",
      "[0.34001395114960886, 2.1304978267991102]\n",
      "[2.3145905171809105, 0.1722063215561446]\n",
      "[0.17530916187432088, 3.0719628415492894]\n",
      "Learning Rate= 0.00029296875\n",
      "[3.2648685968522733, 0.34513750398159454]\n",
      "[0.33989989798687131, 2.1304742242398964]\n",
      "[2.3146976606282053, 0.17214606829994866]\n",
      "[0.17524589957745082, 3.0720620910096996]\n",
      "Learning Rate= 0.000146484375\n",
      "[3.2648555436528928, 0.34507679944069403]\n",
      "[0.3398428875744704, 2.1304624246964323]\n",
      "[2.3147512117049489, 0.17211595772274904]\n",
      "[0.17521428572209805, 3.072111701376012]\n",
      "Learning Rate= 7.32421875e-05\n",
      "[3.2648490098284988, 0.34504645234507791]\n",
      "[0.33981438641071599, 2.1304565253585896]\n",
      "[2.3147779820842636, 0.17210090644417228]\n",
      "[0.1751984831147681, 3.0721365029696397]\n",
      "Learning Rate= 3.662109375e-05\n",
      "[3.264845741111448, 0.34503128009084844]\n",
      "[0.33980013683947563, 2.1304535757981222]\n",
      "[2.3147913659844903, 0.17209338180705228]\n",
      "[0.17519058289082443, 3.0721489028692526]\n",
      "Learning Rate= 1.8310546875e-05\n",
      "[3.2648441063018745, 0.34502369428711216]\n",
      "[0.33979301230651782, 2.1304521010449999]\n",
      "[2.314798057612288, 0.1720896197389922]\n",
      "[0.1751866330487373, 3.0721551025947806]\n",
      "Learning Rate= 9.1552734375e-06\n",
      "[3.2648432887843466, 0.34501990146608663]\n",
      "[0.33978945010320483, 2.130451363675216]\n",
      "[2.314801403345613, 0.17208773876758182]\n",
      "[0.17518465819515922, 3.0721582024014777]\n",
      "Learning Rate= 4.57763671875e-06\n",
      "[3.2648428799973996, 0.34501800507578423]\n",
      "[0.33978766901733998, 2.1304509949920187]\n",
      "[2.3148030761921325, 0.1720867982975309]\n",
      "[0.17518367078523578, 3.0721597522908106]\n",
      "Learning Rate= 2.288818359375e-06\n",
      "[3.2648426755968809, 0.34501705688568557]\n",
      "[0.33978677847835542, 2.1304508106508435]\n",
      "[2.314803912610357, 0.17208632806641891]\n",
      "[0.17518317708449041, 3.072160527231973]\n",
      "Learning Rate= 1.1444091796875e-06\n",
      "[3.2648425733948607, 0.34501658279189934]\n",
      "[0.33978633320985013, 2.1304507184803616]\n",
      "[2.3148043308182098, 0.1720860929518413]\n",
      "[0.17518293023517181, 3.0721609147016782]\n",
      "Learning Rate= 5.7220458984375e-07\n",
      "[3.2648425222934097, 0.34501634574532208]\n",
      "[0.33978611057584418, 2.1304506723951473]\n",
      "[2.3148045399218216, 0.17208597539479706]\n",
      "[0.17518280681077608, 3.072161108436311]\n",
      "Learning Rate= 2.86102294921875e-07\n",
      "[3.264842496742574, 0.3450162272221125]\n",
      "[0.3397859992589029, 2.1304506493525466]\n",
      "[2.3148046444735488, 0.1720859166163361]\n",
      "[0.17518274509864407, 3.0721612053035736]\n",
      "Learning Rate= 1.430511474609375e-07\n",
      "[3.2648424839671288, 0.34501616796052725]\n",
      "[0.33978594360044762, 2.130450637831248]\n",
      "[2.3148046967493929, 0.1720858872271209]\n",
      "[0.17518271424259457, 3.0721612537371907]\n",
      "Learning Rate= 7.152557373046875e-08\n",
      "[3.2648424775793998, 0.34501613832973976]\n",
      "[0.33978591577122386, 2.1304506320705991]\n",
      "[2.3148047228873101, 0.17208587253251717]\n",
      "[0.17518269881457391, 3.0721612779539962]\n",
      "Learning Rate= 3.5762786865234374e-08\n",
      "[3.2648424743855333, 0.34501612351434707]\n",
      "[0.33978590185661289, 2.1304506291902747]\n",
      "[2.3148047359562676, 0.17208586518521621]\n",
      "[0.17518269110056464, 3.0721612900623976]\n",
      "Learning Rate= 1.7881393432617187e-08\n",
      "[3.2648424727886001, 0.34501611610665112]\n",
      "[0.33978589489930777, 2.1304506277501125]\n",
      "[2.3148047424907459, 0.17208586151156596]\n",
      "[0.17518268724356026, 3.0721612961165987]\n",
      "Learning Rate= 8.940696716308593e-09\n",
      "[3.2648424719901321, 0.34501611240280322]\n",
      "[0.33978589142065518, 2.1304506270300316]\n",
      "[2.3148047457579848, 0.17208585967474091]\n",
      "[0.17518268531505807, 3.0721612991436986]\n",
      "Learning Rate= 4.470348358154297e-09\n",
      "[3.2648424715908986, 0.34501611055087927]\n",
      "[0.33978588968132895, 2.1304506266699907]\n",
      "[2.3148047473916042, 0.17208585875632837]\n",
      "[0.175182684350807, 3.0721613006572488]\n",
      "Learning Rate= 2.2351741790771484e-09\n",
      "[3.2648424713912823, 0.34501610962491741]\n",
      "[0.33978588881166583, 2.1304506264899707]\n",
      "[2.314804748208414, 0.17208585829712209]\n",
      "[0.17518268386868152, 3.0721613014140239]\n",
      "Learning Rate= 1.1175870895385742e-09\n",
      "[3.2648424712914741, 0.34501610916193637]\n",
      "[0.33978588837683427, 2.130450626399961]\n",
      "[2.3148047486168193, 0.17208585806751908]\n",
      "[0.17518268362761874, 3.0721613017924119]\n",
      "Learning Rate= 5.587935447692871e-10\n",
      "[3.26484247124157, 0.34501610893044571]\n",
      "[0.33978588815941857, 2.1304506263549556]\n",
      "[2.3148047488210217, 0.17208585795271747]\n",
      "[0.17518268350708732, 3.0721613019816054]\n",
      "Learning Rate= 2.7939677238464354e-10\n",
      "[3.264842471216618, 0.34501610881470057]\n",
      "[0.33978588805071064, 2.1304506263324532]\n",
      "[2.3148047489231232, 0.17208585789531672]\n",
      "[0.17518268344682164, 3.0721613020762022]\n",
      "Learning Rate= 1.3969838619232177e-10\n",
      "[3.2648424712041417, 0.34501610875682787]\n",
      "[0.33978588799635667, 2.1304506263212017]\n",
      "[2.3148047489741734, 0.17208585786661634]\n",
      "[0.17518268341668883, 3.0721613021235008]\n",
      "Learning Rate= 6.984919309616089e-11\n",
      "[3.2648424711979036, 0.34501610872789157]\n",
      "[0.33978588796917969, 2.130450626315576]\n",
      "[2.3148047489996988, 0.17208585785226613]\n",
      "[0.17518268340162238, 3.0721613021471503]\n",
      "Learning Rate= 3.492459654808044e-11\n",
      "[3.2648424711947843, 0.34501610871342347]\n",
      "[0.33978588795559123, 2.1304506263127636]\n",
      "[2.3148047490124615, 0.17208585784509103]\n",
      "[0.17518268339408913, 3.0721613021589746]\n",
      "Learning Rate= 1.746229827404022e-11\n",
      "[3.2648424711932256, 0.34501610870618932]\n",
      "[0.33978588794879705, 2.1304506263113572]\n",
      "[2.314804749018843, 0.17208585784150346]\n",
      "[0.17518268339032247, 3.0721613021648873]\n",
      "Learning Rate= 8.73114913702011e-12\n",
      "[3.2648424711924453, 0.34501610870257238]\n",
      "[0.33978588794539988, 2.1304506263106537]\n",
      "[2.3148047490220334, 0.17208585783970967]\n",
      "[0.1751826833884392, 3.0721613021678431]\n",
      "Learning Rate= 4.365574568510055e-12\n",
      "[3.2648424711920554, 0.34501610870076377]\n",
      "[0.33978588794370135, 2.130450626310302]\n",
      "[2.3148047490236285, 0.17208585783881278]\n",
      "[0.17518268338749757, 3.072161302169321]\n",
      "Learning Rate= 2.1827872842550277e-12\n",
      "[3.2648424711918609, 0.34501610869985966]\n",
      "[0.33978588794285214, 2.1304506263101262]\n",
      "[2.3148047490244261, 0.17208585783836433]\n",
      "[0.17518268338702675, 3.07216130217006]\n",
      "Learning Rate= 1.0913936421275138e-12\n",
      "[3.2648424711917632, 0.34501610869940746]\n",
      "[0.33978588794242737, 2.1304506263100387]\n",
      "[2.3148047490248254, 0.17208585783814012]\n",
      "[0.17518268338679133, 3.0721613021704295]\n",
      "Learning Rate= 5.456968210637569e-13\n",
      "[3.2648424711917148, 0.34501610869918148]\n",
      "[0.33978588794221509, 2.1304506263099947]\n",
      "[2.3148047490250248, 0.17208585783802802]\n",
      "[0.17518268338667364, 3.0721613021706147]\n",
      "Learning Rate= 2.7284841053187846e-13\n",
      "[3.2648424711916899, 0.3450161086990684]\n",
      "[0.3397858879421089, 2.1304506263099725]\n",
      "[2.3148047490251242, 0.17208585783797201]\n",
      "[0.1751826833866148, 3.0721613021707066]\n",
      "Learning Rate= 1.3642420526593923e-13\n",
      "[3.2648424711916784, 0.34501610869901184]\n",
      "[0.33978588794205594, 2.1304506263099614]\n",
      "[2.314804749025174, 0.17208585783794392]\n",
      "[0.17518268338658533, 3.0721613021707528]\n",
      "Learning Rate= 6.821210263296962e-14\n",
      "[3.2648424711916713, 0.34501610869898353]\n",
      "[0.3397858879420293, 2.1304506263099561]\n",
      "[2.3148047490251988, 0.17208585783792993]\n",
      "[0.1751826833865707, 3.0721613021707759]\n",
      "Learning Rate= 3.410605131648481e-14\n",
      "[3.2648424711916686, 0.34501610869896954]\n",
      "[0.33978588794201597, 2.130450626309953]\n",
      "[2.3148047490252113, 0.17208585783792293]\n",
      "[0.17518268338656331, 3.0721613021707879]\n",
      "Learning Rate= 1.7053025658242404e-14\n",
      "[3.2648424711916668, 0.34501610869896226]\n",
      "[0.33978588794200937, 2.1304506263099521]\n",
      "[2.3148047490252175, 0.17208585783791941]\n",
      "[0.17518268338655962, 3.0721613021707936]\n",
      "Learning Rate= 8.526512829121202e-15\n",
      "[3.2648424711916668, 0.34501610869895882]\n",
      "[0.33978588794200604, 2.1304506263099512]\n",
      "[2.314804749025221, 0.17208585783791766]\n",
      "[0.17518268338655782, 3.0721613021707963]\n",
      "Learning Rate= 4.263256414560601e-15\n",
      "[3.2648424711916659, 0.3450161086989571]\n",
      "[0.33978588794200432, 2.1304506263099507]\n",
      "[2.3148047490252224, 0.17208585783791677]\n",
      "[0.17518268338655688, 3.0721613021707976]\n",
      "Learning Rate= 2.1316282072803005e-15\n",
      "[3.2648424711916659, 0.34501610869895616]\n",
      "[0.33978588794200354, 2.1304506263099507]\n",
      "[2.3148047490252228, 0.17208585783791636]\n",
      "[0.1751826833865564, 3.0721613021707981]\n",
      "Learning Rate= 1.0658141036401502e-15\n",
      "[3.2648424711916659, 0.34501610869895577]\n",
      "[0.33978588794200315, 2.1304506263099503]\n",
      "[2.3148047490252233, 0.17208585783791611]\n",
      "[0.17518268338655621, 3.0721613021707985]\n",
      "Learning Rate= 5.329070518200751e-16\n",
      "[3.264842471191665, 0.34501610869895566]\n",
      "[0.33978588794200287, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791602]\n",
      "[0.17518268338655613, 3.072161302170799]\n",
      "Learning Rate= 2.6645352591003756e-16\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791597]\n",
      "[0.17518268338655604, 3.072161302170799]\n",
      "Learning Rate= 1.3322676295501878e-16\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655604, 3.072161302170799]\n",
      "Learning Rate= 6.661338147750939e-17\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.3306690738754695e-17\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.6653345369377347e-17\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 8.326672684688674e-18\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 4.163336342344337e-18\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.0816681711721684e-18\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.0408340855860842e-18\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 5.204170427930421e-19\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.6020852139652105e-19\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.3010426069826053e-19\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 6.505213034913026e-20\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.252606517456513e-20\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.6263032587282566e-20\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 8.131516293641283e-21\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 4.0657581468206415e-21\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.0328790734103207e-21\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.0164395367051604e-21\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 5.082197683525802e-22\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.541098841762901e-22\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.2705494208814505e-22\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 6.352747104407252e-23\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.176373552203626e-23\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.588186776101813e-23\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 7.940933880509065e-24\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.970466940254533e-24\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.9852334701272663e-24\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 9.926167350636332e-25\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 4.963083675318166e-25\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.481541837659083e-25\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.2407709188295415e-25\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 6.203854594147707e-26\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.1019272970738537e-26\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.5509636485369268e-26\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 7.754818242684634e-27\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.877409121342317e-27\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.9387045606711585e-27\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 9.693522803355793e-28\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 4.846761401677896e-28\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 2.423380700838948e-28\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.211690350419474e-28\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 6.05845175209737e-29\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.029225876048685e-29\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.5146129380243426e-29\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 7.573064690121713e-30\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 3.7865323450608565e-30\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 1.8932661725304283e-30\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "Learning Rate= 9.466330862652141e-31\n",
      "[3.264842471191665, 0.34501610869895538]\n",
      "[0.33978588794200276, 2.1304506263099503]\n",
      "[2.3148047490252237, 0.17208585783791594]\n",
      "[0.17518268338655593, 3.072161302170799]\n",
      "[[ 0.00832705  0.99167295]\n",
      " [ 0.02498114  0.41353487]\n",
      " [ 0.5823016   0.02914466]\n",
      " [ 0.99583648  0.01249057]]\n"
     ]
    }
   ],
   "source": [
    "epoch=100\n",
    "distance=[]\n",
    "\n",
    "\n",
    "def dist(x):\n",
    "    distance2=[]\n",
    "    for l in range(0,2):\n",
    "        s=0\n",
    "        W=w[:,l]\n",
    "        for k in range(0,4):\n",
    "            #print(x[k])\n",
    "            #print(W[k])\n",
    "            d=np.power((x[k]-W[k]),2)\n",
    "            #print(d)\n",
    "            s=s+d\n",
    "        #print(s)\n",
    "        distance.append(s)\n",
    "        distance2.append(s)\n",
    "        \n",
    "    return distance2\n",
    "\n",
    "\n",
    "for i in range(0,epoch):\n",
    "    print(\"Learning Rate=\",alpha)\n",
    "    for j in range(0,4):\n",
    "        x=X[j]\n",
    "        element=(dist(x))\n",
    "        m=99999999999\n",
    "        print(element)\n",
    "        for j in range(0,2):\n",
    "            if element[j]<m:\n",
    "                m=element[j]\n",
    "                key=j\n",
    "        uw=w[:,key]\n",
    "        for p in range(0,len(uw)):\n",
    "            w[p][key]=w[p][key]+alpha*(x[p]-w[p][key])\n",
    "\n",
    "\n",
    "        #print(w)\n",
    "        \n",
    "    alpha=alpha/2\n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "#print(distance)\n",
    "print(w)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   1. ]\n",
      " [ 0.   0.5]\n",
      " [ 0.5  0. ]\n",
      " [ 1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "ww=w\n",
    "for h in range(0,4):\n",
    "    for q in range(0,2):\n",
    "        if(ww[h][q]<0.09):\n",
    "            ww[h][q]=0\n",
    "        elif ww[h][q]>0.1 and ww[h][q]<0.80:\n",
    "            ww[h][q]=0.5\n",
    "        else:\n",
    "            ww[h][q]=1\n",
    "\n",
    "print(ww)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.25, 0.25]\n",
      "[0.25, 2.25]\n",
      "[2.25, 0.25]\n",
      "[0.25, 3.25]\n",
      "[2, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "w=ww\n",
    "cluster=[]\n",
    "for j in range(0,4):\n",
    "        x=X[j]\n",
    "        m=99999999999\n",
    "        element=dist(x)\n",
    "        #print(element)\n",
    "        for j in range(0,2):\n",
    "            if element[j]<m:\n",
    "                m=element[j]\n",
    "                key=j\n",
    "        cluster.append(key+1)\n",
    "print(cluster)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 2]\n",
      " [0 0 0 1 1]\n",
      " [1 0 0 0 2]\n",
      " [0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cluster=np.array(cluster)\n",
    "cluster=cluster.reshape(4,1)\n",
    "output=np.concatenate((X, cluster), axis=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
